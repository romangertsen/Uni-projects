library(forecast)   
library(urca)       
library(tseries) 
# Часть 1. Реальные данные 


####################################################################################################
####################### 1.1 Загрузка и преобразование данных.#######################################
####################################################################################################

# файл PG_weekly_close_price.csv содержит недельные цены закрытия акций Procter & Gamble (тикер: PG) за
# последние 5 лет


df <- read.csv("PG_weekly_close_price.csv")
colnames(df)[2] <- "Close_price"

str(df)
head(df)


# проверим корректность временных интервалов
df$Date <- as.Date(df$Date) 
unique(as.numeric(diff(df$Date))) 

# для корректного получения номера недели используем библиотеку lubridate (через %U получилось неверно)
#install.packages('lubridate')



start_year <- isoyear(min(df$Date))
start_week <- isoweek(min(df$Date))

pg_ts <- ts(df$Close_price, start = c(start_year, start_week),frequency = 52)


####################################################################################################
####################### 1.2 Разведочный анализ.#####################################################
####################################################################################################


plot(pg_ts, main = 'Цены закрытия акций Procter & Gamble', ylab = "цена", xlab = "Время")
# явный восходящий тренд 

acf(pg_ts)
# acf убывает очень медленно. значения значимо положительные при больших лагах -> признак нестационарности 

pacf(pg_ts)
# все значения  статистически незначимы. не говорит ни о стационарности, ни о ее отсутствии 

####################################################################################################
####################### 1.3 Стационарность.#########################################################
####################################################################################################

# логарфмируем 
pg_log  <- log(pg_ts)

plot(pg_log, main = 'Логарифм цен закрытия P&G', ylab = "цена", xlab = "Время")

# возьмем первую разность логарфимов 
pg_log_diff  <- diff(pg_log)

tsdisplay(pg_log_diff)
# сам график дохожностей похож на стационарный: колебания вокруг 0, нет тренда, амплитуда примерно одинакова
# acf: почти все столбцы внутри доверительных границ, нет медленно убывающего хвоста, выбросы случаные
# pacf: почти все столбцы внутри доверительных границ. нет выраженной AR структуры. выбросы случайные


# тесты на стационарность 

r <- na.omit(pg_log_diff)

# H0: в ряде есть единичный корень -> ряд нестационарен
adf_res <- ur.df(r,
                 type = "none",        
                 lags = 10,            # максимальное число лагов Δy
                 selectlags = "AIC")   # можно "AIC", "BIC" или "Fixed"
summary(adf_res)
# p-value: < 2.2e-16 -> ряд стационарен 


# KPSS-тест — H0: ряд стационарен
kpss.test(pg_log_diff, null = "Level")
#принимаем H0. Ряд стационарен по итогам двух тестов 



####################################################################################################
####################### 1.4 Подбор и оценка ARIMA.##################################################
####################################################################################################


# напишем функцию (как grid search в sklearn) для перебора параметров модели ARIMA (p, 0, q) 
# (d=0, тк ряд стационарный)

# с учетом графиков acf и pacf (на которых почти все значения внутри доверительного интверала)
# сетка параметров небольшая (p и q не превосходят 5)

arima_grid_search <- function(y,p_max=5,q_max=5){
  results <- data.frame(p=integer(),q=integer(),AIC=numeric(),BIC=numeric())
  
  for(p in 0:p_max) 
    for(q in 0:q_max){
    m <- Arima(y,order=c(p,0,q),include.mean=TRUE,method="ML")
    results <- rbind(results, data.frame(p=p,q=q, AIC=AIC(m),BIC=BIC(m)))
  }
  best_aic <- results[which.min(results$AIC),]
  best_bic <- results[which.min(results$BIC),]
  return(list(results=results,best_AIC_p=best_aic$p,best_AIC_q=best_aic$q, best_BIC_p=best_bic$p,
       best_BIC_q=best_bic$q))
}

grid_search_res <- arima_grid_search(pg_log_diff)

grid_search_res$results

cat('Лучшая модель по AIC: p =', grid_search_res$best_AIC_p, 'q =', grid_search_res$best_AIC_q)
cat('Лучшая модель по BIC: p =', grid_search_res$best_BIC_p, 'q =', grid_search_res$best_BIC_q)

# лучшая модел по AIC: p = 2 q = 2 c лоссами -1213.586 (AIC) -1192.222 (BIC)
# лучшая модел по BIC: p = 0 q = 0 c лоссами -1210.023 (AIC) -1202.901 (BIC)

# оба лосса этих моделей слабо отличаются между собой. 
# тк цель - построить прогноз + длина ряда умеренная -> выбираем по AIC 

m_arma22 <- Arima(pg_log_diff, order = c(2,0,2), include.mean = TRUE)


# проверим, какая модель получится в результате автоподбора 

best_model <- auto.arima(pg_log_diff)
summary(best_model)
# по результатам автоподбора лучшая модель ARIMA(0,0,0)


####################################################################################################
####################### 1.5 Диагностика остатков.###################################################
####################################################################################################

library(forecast)

res <- residuals(m_arma22)

plot(res, main="Остатки модели")
acf(res, main="ACF остатков")
pacf(res, main="PACF остатков")

checkresiduals(m_arma22)

# на графике ACF видно, что почти все значения внутри доверительного интервала (за исключением 
# некоторых небольших выбросов) -> соответствует белому шуму
# результат формального теста также говорит о том, что остатки - белый шум 


####################################################################################################
####################### 1.6 Прогноз и out-of-sample качество.#######################################
####################################################################################################


# последние 20 наблюдений используем как тест
y <- pg_log_diff
T <- length(y)
h <- 20

# Разделяем ряд на train и test по индексам
y_train <- y[1:(T - h)]
y_test  <- y[(T - h + 1):T]

length(y_train)  
length(y_test)   


model_train <- Arima(
  y_train,
  order = c(2, 0, 2),
  include.mean = TRUE,
  method = "ML")

summary(model_train)

# прогноз 
fc <- forecast(model_train, h = length(y_test))

plot(fc,
     main = "Out-of-sample прогноз: train vs test")

lines(
  x = (T - h + 1):T,   
  y = y_test,
  col = "red",
  lwd = 3
)

legend("topleft",
       legend = c("Прогноз", "Фактические (test)"),
       col = c("blue", "red"),
       lwd = c(2, 3),
       bty = "n")


# Оценка качества прогноза на тесте 
accuracy(fc, y_test)

# типичные значения ряда: примерно от −5% до +5%. MAE = 1.6%, RMSE = 2% -> средняя ошибка — это 
# 30–40% от  амплитуды колебаний ряда. Это значимая ошибка,  прогностическая способность модели ограниченная
# это типично для моделирования финансовой доходности, в которой много шума 







# Часть 2. Искусственный временной ряд



####################################################################################################
####################### 2.1 Генерация синтетического ряда ##########################################
####################################################################################################

set.seed(123)   

# получим оценённые параметры модели 
true_coef <- coef(m_arma22)
true_coef

alpha <- true_coef[c("ar1","ar2")]
theta <- true_coef[c("ma1","ma2")]
mu <- true_coef["intercept"]
sigma <- sqrt(m_arma22$sigma2)

n <- length(pg_log_diff)

# генерируем ARMA(2,2) и добавляем среднее mu
y_sim_raw <- arima.sim(model=list(ar= alpha, ma = theta), sd = sigma , n=n)

y_sim <- ts(as.numeric(y_sim_raw + mu), start = start(pg_log_diff), frequency = frequency(pg_log_diff))


####################################################################################################
################################# 2.2 Проверка стационарности ######################################
####################################################################################################

tsdisplay(y_sim, main = 'Cгенерированный ряд')

# H0 — единичный корень 
adf_sim <- ur.df(na.omit(y_sim), type = 'none',lags = 10,selectlags = 'AIC')
summary(adf_sim)
# ряд стационарный 

# H0 — стационарность
kpss.test(y_sim, null = 'Level')
# ряд стационарный


####################################################################################################
################################# 2.3 Подбор и оценка ARIMA для сгенерированного ряда ##############
####################################################################################################

# используем ту же функцию перебора, что и для реального ряда
grid_sim <- arima_grid_search(y_sim)
grid_sim$results

cat('Лучшая модель по AIC: p =', grid_sim$best_AIC_p, 'q =', grid_sim$best_AIC_q)
cat('Лучшая модель по BIC: p =', grid_sim$best_BIC_p, 'q =', grid_sim$best_BIC_q)

# лучшая модел по AIC: p = 2 q = 2 c лоссами -1221.544 (AIC) -1200.180 (BIC)
# лучшая модел по BIC: p = 1 q = 1 c лоссами -1219.374 (AIC) -1205.131 (BIC)

# изменилась лучшая модель по BIC: (0, 0) -> (1, 1)


# в качестве оптимальной модели опять выбираем по AIC
m_sim_arma22_sim <- Arima(y_sim, order = c(2,0,2), include.mean = TRUE, method = "ML")
summary(m_sim_arma22_sim)




####################################################################################################
################################# 2.4 Диагностика остатков синтетической модели ####################
####################################################################################################


res_sim <- residuals(m_sim_arma22_sim)

plot(res_sim, main="Остатки модели")
acf(res_sim, main="ACF остатков")
pacf(res_sim, main="PACF остатков")

checkresiduals(m_sim_arma34_sim)

# остатки - белый шум 


####################################################################################################
################################# 2.5 Прогноз и качество на синтетическом ряду #####################
####################################################################################################


# последние 20 наблюдений используем как тест
y2 <- y_sim
T <- length(y2)
h <- 20

# Разделяем ряд на train и test по индексам
y_train <- y2[1:(T - h)]
y_test  <- y2[(T - h + 1):T]

length(y_train)  
length(y_test)   


model_train <- Arima(
  y_train,
  order = c(2, 0, 2),
  include.mean = TRUE,
  method = "ML")


# прогноз 
fc <- forecast(model_train, h = length(y_test))

plot(fc,
     main = "Out-of-sample прогноз: train vs test")

lines(
  x = (T - h + 1):T,   
  y = y_test,
  col = "red",
  lwd = 3
)

legend("topleft",
       legend = c("Прогноз", "Фактические (test)"),
       col = c("blue", "red"),
       lwd = c(2, 3),
       bty = "n")


# Оценка качества прогноза на тесте 
accuracy(fc, y_test)

# результаты практически не отличются от реальных данных



####################################################################################################
################################# Итоги ############################################################
####################################################################################################


# Синтетический ряд, сгенерированный из ARIMA(2,0,2), оказался стационарным 
# (ADF отвергает единичный корень, KPSS не отвергает стационарность). 
# Повторный подбор модели дал ARIMA(2,0,2) по AIC, то есть исходная структура процесса была 
# восстановлена, а BIC выбрал ARIMA(1,0,1)

# Остатки не содержат автокорреляции (тест Льюнга–Бокса p-value = 0.69).
# Качество прогноза на тестовой выборке изменилось слабо: 
# RMSE 0.02 -> 0.023, MAE 0.016 -> 0.018



